{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DS 301: Applied Data Modeling and Predictive Analysis**\n",
    "\n",
    "# Lab 7 â€“ Random Forests, AdaBoost\n",
    "\n",
    "Nok Wongpiromsarn, 9 October 2020\n",
    "\n",
    "**Instructions:**\n",
    "Perform regression with 'SalePrice' as the output.\n",
    "1. Select at least 2 features of your choice. Explain why you select these features.\n",
    "2. Prepare the data using Pipeline and ColumnTransformer. Explain the reasoning behind having each transformation in the Pipeline. Hint: Consider, e.g., StandardScaler, OneHotEncoder, etc.\n",
    "3. Train the following models\n",
    "   - RandomForestRegressor\n",
    "   - AdaBoostRegressor\n",
    "   - XGBRegressor\n",
    "4. Evaluate each of the above models based on RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the data and allocate some for testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"datasets/house-price.csv\")\n",
    "data_train, data_test = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Select at least 2 features of your choice. Explain why you select these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the features with correlation > 0.55\n",
    "# Essentially, we want to pick features with high correlation.\n",
    "\n",
    "attribs_encoded = data_encoded.columns[abs_corr > 0.55]\n",
    "attribs_encoded = attribs_encoded[(attribs_encoded != \"SalePrice\")]\n",
    "attribs_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert attribs_encoded to the original attributes before one-hot encoding.\n",
    "# Note that the following code assumes that the encoded attribute name is obtained from the original attribute name\n",
    "# by appending \"_\" and that the original attribute names do not include \"_\"\n",
    "\n",
    "attribs = []\n",
    "\n",
    "for a in attribs_encoded:\n",
    "    index = a.find('_')\n",
    "    if index > 0:\n",
    "        a = a[:index]\n",
    "    if a not in attribs:\n",
    "        attribs.append(a)\n",
    "        \n",
    "# Print selected attributes and their corresponding types\n",
    "print(\"Selected {} atrributes\".format(len(attribs)))\n",
    "print(\"  {:15} {:10} {:^10}\".format(\"Column\", \"Dtype\", \"Null Count\"))\n",
    "print(\"  {:15} {:10} {:^10}\".format(\"------\", \"-----\", \"----------\"))\n",
    "for attr in attribs:\n",
    "    print(\"  {:15} {:10} {:^10}\".format(attr, str(data_train[attr].dtype), data_train[attr].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare the data using Pipeline and ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the selected features based on their types\n",
    "\n",
    "num_attribs = [a for a in attribs if data[a].dtypes == 'int64']\n",
    "cat_attribs = [a for a in attribs if data[a].dtypes == 'object']\n",
    "\n",
    "# Ensure that we've covered all the selected features\n",
    "assert len(num_attribs) + len(cat_attribs) == len(attribs)\n",
    "\n",
    "print(num_attribs)\n",
    "print(cat_attribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# We need to scale the features and convert categorical features to numerical ones.\n",
    "# There is no missing values in this case, so there is really no need to use SimpleImputer.\n",
    "# I'll still add SimpleImputer to illustrate how you may use Pipeline, together with ColumnTransformer\n",
    "# to create a complete transformer.\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), num_attribs), # Apply StandardScaler to numerical features\n",
    "    ('cat', cat_transformer, cat_attribs),  # Apply cat_transformer to categorical features\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the following models\n",
    "\n",
    "- RandomForestRegressor\n",
    "- AdaBoostRegressor\n",
    "- XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate each of the above models based on RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rmse_rnd = sqrt(mean_squared_error(y_test, y_pred_rnd))\n",
    "print(\"RMSE RandomForestRegressor: {}\".format(rmse_rnd))\n",
    "\n",
    "rmse_adb = sqrt(mean_squared_error(y_test, y_pred_adb))\n",
    "print(\"RMSE AdaBoostRegressor: {}\".format(rmse_adb))\n",
    "\n",
    "rmse_xgb = sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "print(\"RMSE XGBRegressor: {}\".format(rmse_xgb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
